{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c706017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and leverage the imported file for analysis\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "Tk().withdraw()\n",
    "file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff71cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base name of the file\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Remove the extension from the file name\n",
    "file_name_without_extension = os.path.splitext(file_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e003ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(file_name)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the address columns\n",
    "address_columns = {\n",
    "    'street_and_house_number': ['Addr1','Risk Address','Street'],\n",
    "    'city': ['City','Risk City','city'],\n",
    "    'state_abbreviation': ['State','StateProvCd','Risk State'],\n",
    "    'postal_code': ['Risk Zip Code','PostalCd','Zip','Zip Code'],\n",
    "    'latitude': ['Lat', 'Risk Lat', 'lat','Latitude','latitude'],\n",
    "    'longitude': ['Long','Risk Long','long','Longitude','longitude']\n",
    "    }\n",
    "    \n",
    "# Check if any of the address column names are in the DataFrame\n",
    "address_column_mask = df.columns.isin(\n",
    "    address_columns['street_and_house_number'] +\n",
    "    address_columns['city'] +\n",
    "    address_columns['state_abbreviation'] +\n",
    "    address_columns['postal_code']\n",
    ")\n",
    "\n",
    "# Get the name of the column to use for each component\n",
    "street_and_house_number_col = list(set(df.columns) & set(address_columns['street_and_house_number']))[0]\n",
    "city_col = list(set(df.columns) & set(address_columns['city']))[0]\n",
    "state_abbreviation_col = list(set(df.columns) & set(address_columns['state_abbreviation']))[0]\n",
    "postal_code_col = list(set(df.columns) & set(address_columns['postal_code']))[0]\n",
    "\n",
    "# Select the first column that exists in the DataFrame\n",
    "for column, column_names in address_columns.items():\n",
    "    match = df.columns[df.columns.isin(column_names)].tolist()\n",
    "    if match:\n",
    "        address_columns[column] = match[0]\n",
    "\n",
    "if not any(address_column_mask):\n",
    "    raise ValueError('None of the specified address columns were found in the DataFrame')\n",
    "\n",
    "# Concatenate the address components into a single address string\n",
    "df['address'] = (\n",
    "    df[address_columns['street_and_house_number']].astype(str) + ', ' +\n",
    "    df[address_columns['city']].astype(str) + ', ' +\n",
    "    df[address_columns['state_abbreviation']].astype(str) + ' ' +\n",
    "    df[address_columns['postal_code']].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag duplicates in the address column\n",
    "df['address_duplicate'] = df['address'].duplicated()\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_address_duplicates = df['address_duplicate'].sum()\n",
    "\n",
    "# Count the number of unique addresses\n",
    "num_unique_addresses = len(df['address'].unique())\n",
    "\n",
    "# Calculate the number of address duplicates\n",
    "num_address_duplicates = df['address_duplicate'].sum()\n",
    "\n",
    "# Calculate the percentage of duplicate addresses\n",
    "if num_unique_addresses > 0:\n",
    "    percent_address_duplicates = num_address_duplicates / num_unique_addresses * 100\n",
    "else:\n",
    "    percent_address_duplicates = 0.0\n",
    "\n",
    "# Check if latitude and longitude columns exist in the dataframe\n",
    "lat_long_cols = ['latitude', 'Longitude']\n",
    "missing_cols = [col_name for col_name in lat_long_cols if col_name not in df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(\"The following columns are missing:\", missing_cols)\n",
    "    num_lat_long_duplicates = 0\n",
    "    percent_lat_long_duplicates = 0\n",
    "else:\n",
    "    # Concatenate latitude and longitude columns to create a lat_long column\n",
    "    df['lat_long'] = df['latitude'].astype(str) + ', ' + df['longitude'].astype(str)\n",
    "\n",
    "    # Flag duplicates in the lat_long column\n",
    "    df['lat_long_duplicate'] = df['lat_long'].duplicated()\n",
    "\n",
    "    # Count the number of duplicates\n",
    "    num_lat_long_duplicates = df['lat_long_duplicate'].sum()\n",
    "\n",
    "    # Calculate the percentage of duplicates\n",
    "    percent_lat_long_duplicates = num_lat_long_duplicates / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print('Number of duplicate addresses:', num_address_duplicates)\n",
    "print('Percentage of duplicate addresses:', percent_address_duplicates)\n",
    "print('Number of duplicate lat/long pairs:',num_lat_long_duplicates)\n",
    "print('Percentage of duplicate lat/long pairs:', percent_lat_long_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58582f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the effective date columns\n",
    "effective_date_columns = ['Effective Date', 'EffDate', 'eff_date']\n",
    "\n",
    "# Check if any of the effective date column names are in the DataFrame\n",
    "effective_date_column_mask = df.columns.isin(effective_date_columns)\n",
    "\n",
    "if any(effective_date_column_mask):\n",
    "    # Get the name of the column to use for the effective date\n",
    "    effective_date_col = list(set(df.columns) & set(effective_date_columns))[0]\n",
    "else:\n",
    "    print('No effective date column found in the DataFrame. Count and percentages will be reported as 0.')\n",
    "    effective_date_col = None\n",
    "\n",
    "# Flag duplicates in the effective date column\n",
    "if effective_date_col:\n",
    "    df['effective_date_duplicate'] = df[effective_date_col].duplicated()\n",
    "else:\n",
    "    df['effective_date_duplicate'] = False\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_effective_date_duplicates = df['effective_date_duplicate'].sum()\n",
    "\n",
    "# Calculate the percentage of duplicates\n",
    "if effective_date_col:\n",
    "    percent_effective_date_duplicates = num_effective_date_duplicates / df.shape[0] * 100\n",
    "else:\n",
    "    percent_effective_date_duplicates = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ba157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the effective date column to datetime format if it exists in the DataFrame\n",
    "if effective_date_col in df.columns:\n",
    "    df[effective_date_col] = pd.to_datetime(df[effective_date_col], errors='coerce')\n",
    "\n",
    "    # Find the index of the effective date column\n",
    "    col_index = df.columns.get_loc(effective_date_col)\n",
    "\n",
    "    # Create a new output flag column with values True if the effective date is prior to 2020, False otherwise\n",
    "    df.insert(loc=col_index + 1, column='effective_date_prior_to_2020', value=df[effective_date_col] < '2020-01-01')\n",
    "\n",
    "    # Calculate the percentage of records with the output flag set to True\n",
    "    percent_records = df['effective_date_prior_to_2020'].mean() * 1\n",
    "\n",
    "    print(f\"Percentage of records with effective date prior to 2020: {percent_records}\")\n",
    "\n",
    "    # Count the number of records with effective date prior to 2020\n",
    "    count_records = df[df['effective_date_prior_to_2020'] == True].shape[0]\n",
    "\n",
    "    print(f\"Count of records with effective date prior to 2020: {count_records}\")\n",
    "else:\n",
    "    print(\"No effective date column found in the DataFrame. Count and percentage of records with effective date prior to 2020: 0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the results\n",
    "if any(effective_date_column_mask):\n",
    "    percent_records = df['effective_date_prior_to_2020'].mean() * 1\n",
    "    count_records = df[df['effective_date_prior_to_2020'] == True].shape[0]\n",
    "else:\n",
    "    percent_records = 0\n",
    "    count_records = 0\n",
    "\n",
    "duplicate_results = {'Duplicate Addresses': [num_address_duplicates],\n",
    "                     'Percentage of Duplicate Addresses': percent_address_duplicates / 100,\n",
    "                     'Duplicate Lat/Long Pairs': [num_lat_long_duplicates],\n",
    "                     'Percentage of Duplicate Lat/Long Pairs': percent_lat_long_duplicates / 100,\n",
    "                     'Percentage Before 2020': percent_records,\n",
    "                     'Count Before 2020': count_records}\n",
    "\n",
    "duplicate_results_df = pd.DataFrame(duplicate_results)\n",
    "\n",
    "\n",
    "# Create a file dialog to allow the user to select the save location\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "default_file_name = file_name_without_extension + \"_duplicate_QA_Check.xlsx\"\n",
    "file_path = filedialog.asksaveasfilename(defaultextension='.xlsx', initialfile=default_file_name)\n",
    "\n",
    "\n",
    "# Write the original data to a new Excel file\n",
    "df.to_excel(file_path, engine='openpyxl', index=False)\n",
    "\n",
    "# Append the results to the same Excel file\n",
    "book = openpyxl.load_workbook(file_path)\n",
    "writer = pd.ExcelWriter(file_path, engine='openpyxl')\n",
    "writer.book = book\n",
    "duplicate_results_df.to_excel(writer, sheet_name='Duplicate Results Report', index=False)\n",
    "writer.save()\n",
    "writer.close()\n",
    "print(\"Excel write task completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f4987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
