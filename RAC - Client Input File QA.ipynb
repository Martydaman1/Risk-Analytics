{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ba9343",
   "metadata": {},
   "source": [
    "# Risk Analytics - Client Input File Quality Assuance Check\n",
    "\n",
    "This code helps you identify and flag duplicates in an excel file. It includes:\n",
    "\n",
    "-Importing the required libraries such as Pandas, Openpyxl, os and tkinter.\n",
    "\n",
    "-Allows the user to select the excel file to analyze and extract the file name.\n",
    "\n",
    "-Defines the possible names of the address and effective date columns.\n",
    "\n",
    "-Checks if any of the address column names are in the DataFrame and extract the address components.\n",
    "\n",
    "-Flag duplicates in the address column and count the number of unique addresses and the percentage of duplicate addresses.\n",
    "\n",
    "-Concatenates latitude and longitude columns to create a lat_long column and flags duplicates in the lat_long column. It then counts the number of duplicates and calculates the percentage of duplicates.\n",
    "\n",
    "-Checks if the effective date column exists in the DataFrame, converts it to datetime format and creates a new output flag column with values True if the effective date is prior to 2020, False otherwise. It then calculates the percentage of records with the output flag set to True and counts the number of records with effective date prior to 2020.\n",
    "\n",
    "-Creates a DataFrame with the count and percentages of the address duplicates, lat/long duplicates, effective date duplicates, and records prior to 2020.\n",
    "\n",
    "-The results are written to a new Excel file that contains both the original data and the duplicate report. The user can select the save location using the file dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c706017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and leverage the imported file for analysis\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "Tk().withdraw()\n",
    "file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff71cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base name of the file\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Remove the extension from the file name\n",
    "file_name_without_extension = os.path.splitext(file_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e003ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(file_name)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the address columns\n",
    "address_columns = {\n",
    "    'street_and_house_number': ['Addr1','Risk Address','Street','address'],\n",
    "    'city': ['City','Risk City','city'],\n",
    "    'state_abbreviation': ['State','StateProvCd','Risk State','state'],\n",
    "    'postal_code': ['Risk Zip Code','PostalCd','Zip','Zip Code','PostalCode','zip','Risk Zip'],\n",
    "    'latitude': ['Lat', 'Risk Lat', 'lat','Latitude','latitude','Risk Latitude'],\n",
    "    'longitude': ['Long','Risk Long','long','Longitude','longitude','Risk Longitude']\n",
    "    }\n",
    "    \n",
    "# Check if any of the address column names are in the DataFrame\n",
    "address_column_mask = df.columns.isin(\n",
    "    address_columns['street_and_house_number'] +\n",
    "    address_columns['city'] +\n",
    "    address_columns['state_abbreviation'] +\n",
    "    address_columns['postal_code']\n",
    ")\n",
    "\n",
    "# Get the name of the column to use for each component\n",
    "street_and_house_number_col = list(set(df.columns) & set(address_columns['street_and_house_number']))[0]\n",
    "city_col = list(set(df.columns) & set(address_columns['city']))[0]\n",
    "state_abbreviation_col = list(set(df.columns) & set(address_columns['state_abbreviation']))[0]\n",
    "postal_code_col = list(set(df.columns) & set(address_columns['postal_code']))[0]\n",
    "\n",
    "# Select the first column that exists in the DataFrame\n",
    "for column, column_names in address_columns.items():\n",
    "    match = df.columns[df.columns.isin(column_names)].tolist()\n",
    "    if match:\n",
    "        address_columns[column] = match[0]\n",
    "\n",
    "if not any(address_column_mask):\n",
    "    raise ValueError('None of the specified address columns were found in the DataFrame')\n",
    "\n",
    "# Concatenate the address components into a single address string\n",
    "df['address'] = (\n",
    "    df[address_columns['street_and_house_number']].astype(str) + ', ' +\n",
    "    df[address_columns['city']].astype(str) + ', ' +\n",
    "    df[address_columns['state_abbreviation']].astype(str) + ' ' +\n",
    "    df[address_columns['postal_code']].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag duplicates in the address column\n",
    "df['address_duplicate'] = df['address'].duplicated()\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_address_duplicates = df['address_duplicate'].sum()\n",
    "\n",
    "# Count the number of unique addresses\n",
    "num_unique_addresses = len(df['address'].unique())\n",
    "\n",
    "# Calculate the percentage of duplicate addresses\n",
    "if num_unique_addresses > 0:\n",
    "    percent_address_duplicates = num_address_duplicates / num_unique_addresses * 100\n",
    "else:\n",
    "    percent_address_duplicates = 0.0\n",
    "\n",
    "# Check if any latitude and longitude columns exist in the dataframe\n",
    "if not any(df.columns.isin([address_columns['latitude']])):\n",
    "    missing_latitude_cols = [address_columns['latitude']]\n",
    "else:\n",
    "    missing_latitude_cols = []\n",
    "\n",
    "if not any(df.columns.isin([address_columns['longitude']])):\n",
    "    missing_longitude_cols = [address_columns['longitude']]\n",
    "else:\n",
    "    missing_longitude_cols = []\n",
    "\n",
    "missing_categories = []\n",
    "if missing_latitude_cols:\n",
    "    missing_categories.append('latitude')\n",
    "if missing_longitude_cols:\n",
    "    missing_categories.append('longitude')\n",
    "\n",
    "if missing_categories:\n",
    "    print(\"The following categories are missing:\", missing_categories)\n",
    "    num_lat_long_duplicates = 0\n",
    "    percent_lat_long_duplicates = 0\n",
    "else:\n",
    "    # Select the first column that exists in the DataFrame for latitude and longitude\n",
    "    lat_col = df.columns[df.columns.isin([address_columns['latitude']])].tolist()[0]\n",
    "    long_col = df.columns[df.columns.isin([address_columns['longitude']])].tolist()[0]\n",
    "\n",
    "    # Concatenate latitude and longitude columns to create a lat_long column\n",
    "    df['lat_long'] = df[lat_col].astype(str) + ', ' + df[long_col].astype(str)\n",
    "\n",
    "    # Flag duplicates in the lat_long column\n",
    "    df['lat_long_duplicate'] = df['lat_long'].duplicated()\n",
    "\n",
    "    # Count the number of duplicates\n",
    "    num_lat_long_duplicates = df['lat_long_duplicate'].sum()\n",
    "\n",
    "    # Calculate the percentage of duplicates\n",
    "    percent_lat_long_duplicates = num_lat_long_duplicates / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_48_states = ['AL', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# Define a regular expression pattern to match any string that is not a lower 48 state abbreviation\n",
    "pattern = re.compile(r'\\b(?!(DC|PR|VI|GU|AS))[A-Z]{2}\\b')\n",
    "\n",
    "# Check if the state_abbreviation column exists in the DataFrame\n",
    "if state_abbreviation_col not in df.columns:\n",
    "    raise ValueError('The specified state_abbreviation column was not found in the DataFrame')\n",
    "\n",
    "# Convert the state_abbreviation column to string\n",
    "df[state_abbreviation_col] = df[state_abbreviation_col].astype(str)\n",
    "\n",
    "# Count the number of non-lower-48 state abbreviations in the state_abbreviation column\n",
    "non_lower_48_count = df[state_abbreviation_col].apply(lambda x: pattern.match(x) is not None).sum()\n",
    "\n",
    "# Flag all instances of non-lower-48 state abbreviations in the state_abbreviation column\n",
    "df['is_non_lower_48_state'] = df[state_abbreviation_col].apply(lambda x: x not in lower_48_states)\n",
    "\n",
    "# Count the number of lower-48 state abbreviations in the state_abbreviation column\n",
    "lower_48_count = df[state_abbreviation_col].apply(lambda x: x in lower_48_states).sum()\n",
    "\n",
    "# Print the total and lower-48 state counts\n",
    "total_count = len(df[state_abbreviation_col])\n",
    "print('total_count:', total_count)\n",
    "print('lower_48_count:', lower_48_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print('Number of duplicate addresses:', num_address_duplicates)\n",
    "print('Percentage of duplicate addresses:', percent_address_duplicates)\n",
    "print('Number of duplicate lat/long pairs:',num_lat_long_duplicates)\n",
    "print('Percentage of duplicate lat/long pairs:', percent_lat_long_duplicates)\n",
    "print('Out of Contiguous 48 States :', total_count - lower_48_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58582f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the effective date columns\n",
    "effective_date_columns = ['Effective Date', 'EffDate', 'eff_date','effective_date']\n",
    "\n",
    "# Check if any of the effective date column names are in the DataFrame\n",
    "effective_date_column_mask = df.columns.isin(effective_date_columns)\n",
    "\n",
    "if any(effective_date_column_mask):\n",
    "    # Get the name of the column to use for the effective date\n",
    "    effective_date_col = list(set(df.columns) & set(effective_date_columns))[0]\n",
    "else:\n",
    "    print('No effective date column found in the DataFrame. Count and percentages will be reported as 0.')\n",
    "    effective_date_col = None\n",
    "\n",
    "# Flag duplicates in the effective date column\n",
    "if effective_date_col:\n",
    "    df['effective_date_duplicate'] = df[effective_date_col].duplicated()\n",
    "else:\n",
    "    df['effective_date_duplicate'] = False\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_effective_date_duplicates = df['effective_date_duplicate'].sum()\n",
    "\n",
    "# Calculate the percentage of duplicates\n",
    "if effective_date_col:\n",
    "    percent_effective_date_duplicates = num_effective_date_duplicates / df.shape[0] * 100\n",
    "else:\n",
    "    percent_effective_date_duplicates = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ba157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the effective date column to datetime format if it exists in the DataFrame\n",
    "if effective_date_col in df.columns:\n",
    "    df[effective_date_col] = pd.to_datetime(df[effective_date_col], errors='coerce')\n",
    "\n",
    "    # Find the index of the effective date column\n",
    "    col_index = df.columns.get_loc(effective_date_col)\n",
    "\n",
    "    # Create a new output flag column with values True if the effective date is prior to 2020, False otherwise\n",
    "    df.insert(loc=col_index + 1, column='effective_date_prior_to_2020', value=df[effective_date_col] < '2020-01-01')\n",
    "\n",
    "    # Calculate the percentage of records with the output flag set to True\n",
    "    percent_records = df['effective_date_prior_to_2020'].mean() * 1\n",
    "\n",
    "    print(f\"Percentage of records with effective date prior to 2020: {percent_records}\")\n",
    "\n",
    "    # Count the number of records with effective date prior to 2020\n",
    "    count_records = df[df['effective_date_prior_to_2020'] == True].shape[0]\n",
    "\n",
    "    print(f\"Count of records with effective date prior to 2020: {count_records}\")\n",
    "else:\n",
    "    print('No effective date column found in the DataFrame. Count and percentages will be reported as 0.')\n",
    "    effective_date_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the results\n",
    "duplicate_results = {\n",
    "    'Duplicate Addresses': [num_address_duplicates],\n",
    "    'Percentage of Duplicate Addresses': [percent_address_duplicates / 100],\n",
    "    'Duplicate Lat/Long Pairs': [num_lat_long_duplicates],\n",
    "    'Percentage of Duplicate Lat/Long Pairs': [percent_lat_long_duplicates / 100],\n",
    "    'Duplicate Effective Dates': [num_effective_date_duplicates],\n",
    "    'Percentage of Effective Date Duplicates': [percent_effective_date_duplicates / 100],\n",
    "    'Out of Contiguous 48 States' :[total_count - lower_48_count],\n",
    "}\n",
    "\n",
    "if effective_date_col is not None:\n",
    "    duplicate_results['Percentage Before 2020'] = [percent_records]\n",
    "    duplicate_results['Count Before 2020'] = [count_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5b6ea-3166-471d-a2af-dd2b70313a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'Effective Date' exists and concatenate it with the address\n",
    "if 'Effective Date' in df.columns:\n",
    "    df['Full_Address_with_Date'] = df['Concatenated Address'].astype(str) + ' ' + df['Effective Date'].astype(str)\n",
    "    df['Address_with_Date_Duplicate'] = df.duplicated(subset=['Full_Address_with_Date'], keep=False)\n",
    "    num_address_date_duplicates = df['Address_with_Date_Duplicate'].sum()\n",
    "    percent_address_date_duplicates = (num_address_date_duplicates / total_count) * 100\n",
    "else:\n",
    "    df['Address_with_Date_Duplicate'] = False\n",
    "    num_address_date_duplicates = 0\n",
    "    percent_address_date_duplicates = 0\n",
    "\n",
    "# Add the new calculations to the duplicate_results dictionary\n",
    "duplicate_results['Duplicate Address with Date'] = [num_address_date_duplicates]\n",
    "duplicate_results['Percentage of Duplicate Address with Date'] = [percent_address_date_duplicates / 100]\n",
    "\n",
    "# Create a dataframe with the results\n",
    "duplicate_results_df = pd.DataFrame(duplicate_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file dialog to allow the user to select the save location\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "default_file_name = file_name_without_extension + \"_duplicate_QA_Check.xlsx\"\n",
    "file_path = filedialog.asksaveasfilename(defaultextension='.xlsx', initialfile=default_file_name)\n",
    "\n",
    "print(\"Original sheet with new name created...wait for QA data to process\")\n",
    "\n",
    "# Write the original data and the results to separate sheets in a new Excel file\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name='Original Data', index=False)\n",
    "    duplicate_results_df.to_excel(writer, sheet_name='Duplicate Results Report', index=False)\n",
    "\n",
    "print(\"QA data processing...\")      \n",
    "print(\"Excel write task completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d42306-1ca0-4f4f-a1b5-f91a940fb3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
