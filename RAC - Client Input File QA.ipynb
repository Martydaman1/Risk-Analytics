{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ba9343",
   "metadata": {},
   "source": [
    "# Risk Analytics - Client Input File Quality Assuance Check\n",
    "\n",
    "This code helps you identify and flag duplicates in an excel file. It includes:\n",
    "\n",
    "-Importing the required libraries such as Pandas, Openpyxl, os and tkinter.\n",
    "\n",
    "-Allows the user to select the excel file to analyze and extract the file name.\n",
    "\n",
    "-Defines the possible names of the address and effective date columns.\n",
    "\n",
    "-Checks if any of the address column names are in the DataFrame and extract the address components.\n",
    "\n",
    "-Flag duplicates in the address column and count the number of unique addresses and the percentage of duplicate addresses.\n",
    "\n",
    "-Concatenates latitude and longitude columns to create a lat_long column and flags duplicates in the lat_long column. It then counts the number of duplicates and calculates the percentage of duplicates.\n",
    "\n",
    "-Checks if the effective date column exists in the DataFrame, converts it to datetime format and creates a new output flag column with values True if the effective date is prior to 2020, False otherwise. It then calculates the percentage of records with the output flag set to True and counts the number of records with effective date prior to 2020.\n",
    "\n",
    "-Creates a DataFrame with the count and percentages of the address duplicates, lat/long duplicates, effective date duplicates, and records prior to 2020.\n",
    "\n",
    "-The results are written to a new Excel file that contains both the original data and the duplicate report. The user can select the save location using the file dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c706017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and leverage the imported file for analysis\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "Tk().withdraw()\n",
    "file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff71cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base name of the file\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Remove the extension from the file name\n",
    "file_name_without_extension = os.path.splitext(file_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e003ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zesty_20230406_Input_RM.xlsx\n",
      "Index(['Address_ID', 'Unnamed: 1', 'Risk Address', 'AddressLine2',\n",
      "       'AddressLine3', 'Risk City', 'State', 'Risk Zip Code', 'Latitude',\n",
      "       'Longitude', 'Effective Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(file_name)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3661b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the address columns\n",
    "address_columns = {\n",
    "    'street_and_house_number': ['Addr1','Risk Address','Street'],\n",
    "    'city': ['City','Risk City','city'],\n",
    "    'state_abbreviation': ['State','StateProvCd','Risk State'],\n",
    "    'postal_code': ['Risk Zip Code','PostalCd','Zip','Zip Code','PostalCode'],\n",
    "    'latitude': ['Lat', 'Risk Lat', 'lat','Latitude','latitude'],\n",
    "    'longitude': ['Long','Risk Long','long','Longitude','longitude']\n",
    "    }\n",
    "    \n",
    "# Check if any of the address column names are in the DataFrame\n",
    "address_column_mask = df.columns.isin(\n",
    "    address_columns['street_and_house_number'] +\n",
    "    address_columns['city'] +\n",
    "    address_columns['state_abbreviation'] +\n",
    "    address_columns['postal_code']\n",
    ")\n",
    "\n",
    "# Get the name of the column to use for each component\n",
    "street_and_house_number_col = list(set(df.columns) & set(address_columns['street_and_house_number']))[0]\n",
    "city_col = list(set(df.columns) & set(address_columns['city']))[0]\n",
    "state_abbreviation_col = list(set(df.columns) & set(address_columns['state_abbreviation']))[0]\n",
    "postal_code_col = list(set(df.columns) & set(address_columns['postal_code']))[0]\n",
    "\n",
    "# Select the first column that exists in the DataFrame\n",
    "for column, column_names in address_columns.items():\n",
    "    match = df.columns[df.columns.isin(column_names)].tolist()\n",
    "    if match:\n",
    "        address_columns[column] = match[0]\n",
    "\n",
    "if not any(address_column_mask):\n",
    "    raise ValueError('None of the specified address columns were found in the DataFrame')\n",
    "\n",
    "# Concatenate the address components into a single address string\n",
    "df['address'] = (\n",
    "    df[address_columns['street_and_house_number']].astype(str) + ', ' +\n",
    "    df[address_columns['city']].astype(str) + ', ' +\n",
    "    df[address_columns['state_abbreviation']].astype(str) + ' ' +\n",
    "    df[address_columns['postal_code']].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0082819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag duplicates in the address column\n",
    "df['address_duplicate'] = df['address'].duplicated()\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_address_duplicates = df['address_duplicate'].sum()\n",
    "\n",
    "# Count the number of unique addresses\n",
    "num_unique_addresses = len(df['address'].unique())\n",
    "\n",
    "# Calculate the number of address duplicates\n",
    "num_address_duplicates = df['address_duplicate'].sum()\n",
    "\n",
    "# Calculate the percentage of duplicate addresses\n",
    "if num_unique_addresses > 0:\n",
    "    percent_address_duplicates = num_address_duplicates / num_unique_addresses * 100\n",
    "else:\n",
    "    percent_address_duplicates = 0.0\n",
    "\n",
    "# Check if latitude and longitude columns exist in the dataframe\n",
    "missing_cols = [col_name for col_name in [address_columns['latitude'], address_columns['longitude']] if col_name not in df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(\"The following columns are missing:\", missing_cols)\n",
    "    num_lat_long_duplicates = 0\n",
    "    percent_lat_long_duplicates = 0\n",
    "else:\n",
    "    # Concatenate latitude and longitude columns to create a lat_long column\n",
    "    df['lat_long'] = df[address_columns['latitude']].astype(str) + ', ' + df[address_columns['longitude']].astype(str)\n",
    "\n",
    "    # Flag duplicates in the lat_long column\n",
    "    df['lat_long_duplicate'] = df['lat_long'].duplicated()\n",
    "\n",
    "    # Count the number of duplicates\n",
    "    num_lat_long_duplicates = df['lat_long_duplicate'].sum()\n",
    "\n",
    "    # Calculate the percentage of duplicates\n",
    "    percent_lat_long_duplicates = num_lat_long_duplicates / df.shape[0] * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e526e86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count: 250000\n",
      "lower_48_count: 250000\n"
     ]
    }
   ],
   "source": [
    "lower_48_states = ['AL', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# Define a regular expression pattern to match any string that is not a lower 48 state abbreviation\n",
    "pattern = re.compile(r'\\b(?!(DC|PR|VI|GU|AS))[A-Z]{2}\\b')\n",
    "\n",
    "# Check if the state_abbreviation column exists in the DataFrame\n",
    "if state_abbreviation_col not in df.columns:\n",
    "    raise ValueError('The specified state_abbreviation column was not found in the DataFrame')\n",
    "\n",
    "# Count the number of non-lower-48 state abbreviations in the state_abbreviation column\n",
    "non_lower_48_count = df[state_abbreviation_col].apply(lambda x: pattern.match(x) is not None).sum()\n",
    "\n",
    "# Flag all instances of non-lower-48 state abbreviations in the state_abbreviation column\n",
    "df['is_non_lower_48_state'] = df[state_abbreviation_col].apply(lambda x: x not in lower_48_states)\n",
    "\n",
    "# Count the number of lower-48 state abbreviations in the state_abbreviation column\n",
    "lower_48_count = df[state_abbreviation_col].apply(lambda x: x in lower_48_states).sum()\n",
    "\n",
    "# Print the total and lower-48 state counts\n",
    "total_count = len(df[state_abbreviation_col])\n",
    "print('total_count:', total_count)\n",
    "print('lower_48_count:', lower_48_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252bdc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate addresses: 0\n",
      "Percentage of duplicate addresses: 0.0\n",
      "Number of duplicate lat/long pairs: 249999\n",
      "Percentage of duplicate lat/long pairs: 99.9996\n",
      "Out of Contiguous 48 States : 0\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print('Number of duplicate addresses:', num_address_duplicates)\n",
    "print('Percentage of duplicate addresses:', percent_address_duplicates)\n",
    "print('Number of duplicate lat/long pairs:',num_lat_long_duplicates)\n",
    "print('Percentage of duplicate lat/long pairs:', percent_lat_long_duplicates)\n",
    "print('Out of Contiguous 48 States :', total_count - lower_48_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58582f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the effective date columns\n",
    "effective_date_columns = ['Effective Date', 'EffDate', 'eff_date']\n",
    "\n",
    "# Check if any of the effective date column names are in the DataFrame\n",
    "effective_date_column_mask = df.columns.isin(effective_date_columns)\n",
    "\n",
    "if any(effective_date_column_mask):\n",
    "    # Get the name of the column to use for the effective date\n",
    "    effective_date_col = list(set(df.columns) & set(effective_date_columns))[0]\n",
    "else:\n",
    "    print('No effective date column found in the DataFrame. Count and percentages will be reported as 0.')\n",
    "    effective_date_col = None\n",
    "\n",
    "# Flag duplicates in the effective date column\n",
    "if effective_date_col:\n",
    "    df['effective_date_duplicate'] = df[effective_date_col].duplicated()\n",
    "else:\n",
    "    df['effective_date_duplicate'] = False\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_effective_date_duplicates = df['effective_date_duplicate'].sum()\n",
    "\n",
    "# Calculate the percentage of duplicates\n",
    "if effective_date_col:\n",
    "    percent_effective_date_duplicates = num_effective_date_duplicates / df.shape[0] * 100\n",
    "else:\n",
    "    percent_effective_date_duplicates = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5ba157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of records with effective date prior to 2020: 0.0\n",
      "Count of records with effective date prior to 2020: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert the effective date column to datetime format if it exists in the DataFrame\n",
    "if effective_date_col in df.columns:\n",
    "    df[effective_date_col] = pd.to_datetime(df[effective_date_col], errors='coerce')\n",
    "\n",
    "    # Find the index of the effective date column\n",
    "    col_index = df.columns.get_loc(effective_date_col)\n",
    "\n",
    "    # Create a new output flag column with values True if the effective date is prior to 2020, False otherwise\n",
    "    df.insert(loc=col_index + 1, column='effective_date_prior_to_2020', value=df[effective_date_col] < '2020-01-01')\n",
    "\n",
    "    # Calculate the percentage of records with the output flag set to True\n",
    "    percent_records = df['effective_date_prior_to_2020'].mean() * 1\n",
    "\n",
    "    print(f\"Percentage of records with effective date prior to 2020: {percent_records}\")\n",
    "\n",
    "    # Count the number of records with effective date prior to 2020\n",
    "    count_records = df[df['effective_date_prior_to_2020'] == True].shape[0]\n",
    "\n",
    "    print(f\"Count of records with effective date prior to 2020: {count_records}\")\n",
    "else:\n",
    "    print(\"No effective date column found in the DataFrame. Count and percentage of records with effective date prior to 2020: 0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da83accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if latitude and longitude columns exist in the dataframe\n",
    "missing_cols = [col_name for col_name in [address_columns['latitude'], address_columns['longitude']] if col_name not in df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(\"The following columns are missing:\", missing_cols)\n",
    "    num_lat_long_duplicates = 0\n",
    "    percent_lat_long_duplicates = 0\n",
    "else:\n",
    "    # Concatenate latitude and longitude columns to create a lat_long column\n",
    "    df['lat_long'] = df[address_columns['latitude']].astype(str) + ', ' + df[address_columns['longitude']].astype(str)\n",
    "\n",
    "    # Flag duplicates in the lat_long column\n",
    "    df['lat_long_duplicate'] = df['lat_long'].duplicated()\n",
    "\n",
    "    # Count the number of duplicates\n",
    "    num_lat_long_duplicates = df['lat_long_duplicate'].sum()\n",
    "\n",
    "    # Calculate the percentage of duplicates\n",
    "    percent_lat_long_duplicates = num_lat_long_duplicates / df.shape[0] * 100\n",
    "\n",
    "# Check if effective date column exists in the dataframe\n",
    "if effective_date_col in df.columns:\n",
    "    # Flag duplicates in the effective date column\n",
    "    df['effective_date_duplicate'] = df[effective_date_col].duplicated()\n",
    "\n",
    "    # Count the number of duplicates\n",
    "    num_effective_date_duplicates = df['effective_date_duplicate'].sum()\n",
    "\n",
    "    # Calculate the percentage of duplicates\n",
    "    percent_effective_date_duplicates = num_effective_date_duplicates / df.shape[0] * 100\n",
    "else:\n",
    "    num_effective_date_duplicates = 0\n",
    "    percent_effective_date_duplicates = 0\n",
    "\n",
    "# Create a dataframe with the results\n",
    "duplicate_results = {\n",
    "    'Duplicate Addresses': [num_address_duplicates],\n",
    "    'Percentage of Duplicate Addresses': [percent_address_duplicates / 100],\n",
    "    'Duplicate Lat/Long Pairs': [num_lat_long_duplicates],\n",
    "    'Percentage of Duplicate Lat/Long Pairs': [percent_lat_long_duplicates / 100],\n",
    "    'Percentage Before 2020': [percent_records],\n",
    "    'Count Before 2020': [count_records],\n",
    "    'Duplicate Effective Dates': [num_effective_date_duplicates],\n",
    "    'Percentage of Effective Date Duplicates': [percent_effective_date_duplicates / 100],\n",
    "    'Out of Contiguous 48 States' :[total_count - lower_48_count],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d313f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel write task completed.\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with the results\n",
    "duplicate_results_df = pd.DataFrame(duplicate_results)\n",
    "\n",
    "# Create a file dialog to allow the user to select the save location\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "default_file_name = file_name_without_extension + \"_duplicate_QA_Check.xlsx\"\n",
    "file_path = filedialog.asksaveasfilename(defaultextension='.xlsx', initialfile=default_file_name)\n",
    "\n",
    "# Write the original data to a new Excel file\n",
    "df.to_excel(file_path, engine='openpyxl', index=False)\n",
    "\n",
    "# Append the results to the same Excel file\n",
    "book = openpyxl.load_workbook(file_path)\n",
    "writer = pd.ExcelWriter(file_path, engine='openpyxl')\n",
    "writer.book = book\n",
    "duplicate_results_df.to_excel(writer, sheet_name='Duplicate Results Report', index=False)\n",
    "writer.save()\n",
    "writer.close()\n",
    "print(\"Excel write task completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
