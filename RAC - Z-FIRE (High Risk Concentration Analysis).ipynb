{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d520d9d6",
   "metadata": {},
   "source": [
    "# Concentration of risk analysis for Z-FIRE Scores\n",
    "\n",
    "The following notebook is designed for portfolio level risk analytics that focus on concentration analysis. The code performs the following steps:\n",
    "\n",
    "-Prompts the user to select an Excel file to import.  \n",
    "-Reads the selected file and its contents into a Pandas dataframe.  \n",
    "-Extracts the necessary columns and data to perform geospatial concentration analysis.  \n",
    "-Utilizes the machine learning algorithm DBSCAN to perform unsupervised geospatial clustering.  \n",
    "-Clusters the property locations within the file by a user-defined radius.  \n",
    "-Filters the geospatial clusters to focus on clusters that contain user-defined risk levels.  \n",
    "-Creates a list of clusters and a count of properties in each cluster.  \n",
    "-Creates a list of object IDs within each cluster.  \n",
    "-Generates an interactive HTML map that displays clusters, cluster names, object IDs within the clusters, and a count of properties in each cluster.  \n",
    "-Saves an HTML file with the above-mentioned map in the notebook directory.  \n",
    "-Creates an Excel file that contains a clustering analysis report on two sheets.  \n",
    "-Prompts the user to save the Excel file using a dialog window with a predefined default name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and leverage the imported file for analysis\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog\n",
    "import folium\n",
    "from sklearn.cluster import DBSCAN\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "Tk().withdraw()\n",
    "file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a48aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base name of the file\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Remove the extension from the file name\n",
    "file_name_without_extension = os.path.splitext(file_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98019e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(file_name)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6871a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Excel file into DataFrame\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f77e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Lat/Long points on earth to km radius to be used as Eplison input value\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf27378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the Z-Fire scores along with the other needed columns into the dataframe\n",
    "\n",
    "# Check the data types and make any necessary changes\n",
    "df['level_1'] = pd.to_numeric(df['level_1'])\n",
    "df['level_2'] = pd.to_numeric(df['level_2'])\n",
    "\n",
    "# Select desired columns\n",
    "df = df[['ObjectID', 'Latitude', 'Longitude', 'level_1', 'level_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the clustering parameters\n",
    "km_epsilon = 1.101852 # distance in kilometers\n",
    "epsilon = km_epsilon / 1000 / 111.32  # convert to radians\n",
    "\n",
    "minimum_samples = 3\n",
    "\n",
    "# Cluster the data using DBSCAN\n",
    "dbscan = DBSCAN(eps=epsilon, min_samples=minimum_samples)\n",
    "clusters = dbscan.fit_predict(df[['Longitude', 'Latitude']])\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "df['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75494bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of high-risk number pairs.  These are Z-Fire scores with a conditional probability of .007 or more.\n",
    "high_risk_pairs = [(4, 7),(6, 3),(5, 5),(4, 8),(7, 3),(5, 6),(9, 2),(6, 4),(8, 3),(4, 9),(5, 7),(7, 4),(6, 5),(8, 4),(4, 10),\n",
    "                   (7, 5),(10, 2),(5, 8),(6, 6),(9, 3),(8, 5),(7, 6),(6, 7),(5, 9),(9, 4),(8, 6),(7, 7),(10, 3),(5, 10),(6, 8),\n",
    "                   (9, 5),(8, 7),(7, 8),(6, 9),(10, 4),(9, 6),(8, 8),(7, 9),(6, 10),(10, 5),(9, 7),(8, 9),(7, 10),(10, 6),(9, 8)\n",
    "                   ,(8, 10),(10, 7),(9, 9),(10, 8),(9, 10),(10, 9),(10, 10)]\n",
    "\n",
    "# Filter the high-risk locations\n",
    "high_risk = df[(df[['level_1', 'level_2']].apply(tuple, axis=1)).isin(high_risk_pairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map centered on the mean latitude and longitude\n",
    "center_lat = df['Latitude'].mean()\n",
    "center_long = df['Longitude'].mean()\n",
    "map = folium.Map(location=[center_lat, center_long], zoom_start=10)\n",
    "\n",
    "# Add the high risk locations to the map and label the clusters\n",
    "for cluster_id in high_risk['Cluster'].unique():\n",
    "    cluster_data = high_risk[high_risk['Cluster'] == cluster_id]\n",
    "    if cluster_id == -1:\n",
    "        color = 'red'\n",
    "        cluster_name = 'Noise'\n",
    "    else:\n",
    "        color = 'green'\n",
    "        cluster_name = f'Cluster {cluster_id}'\n",
    "    cluster_count = len(cluster_data)\n",
    "    folium.CircleMarker(location=[cluster_data['Latitude'].mean(), cluster_data['Longitude'].mean()],\n",
    "                        radius=3,\n",
    "                        color=color,\n",
    "                        tooltip=f'{cluster_name}, Count: {cluster_count}',\n",
    "                        popup=f'Cluster Properties: {cluster_data[\"ObjectID\"].tolist()}').add_to(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee22d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of cluster counts\n",
    "cluster_counts = high_risk.groupby('Cluster')['ObjectID'].count()\n",
    "print('\\nCluster Counts:')\n",
    "for cluster_id, count in cluster_counts.items():\n",
    "    if cluster_id == -1:\n",
    "        cluster_name = 'Noise'\n",
    "    else:\n",
    "        cluster_name = f'Cluster {cluster_id}'\n",
    "    print(f'{cluster_name}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add18696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1521252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the name without extension to create a new file name\n",
    "new_file_name = file_name_without_extension + '_concentration_analysis' + '.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the map to HTML with the new file name\n",
    "map.save(new_file_name)\n",
    "print(\"Map Saved to Directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_properties = df.groupby('Cluster')['ObjectID'].agg(list)\n",
    "print(clustered_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae32f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file dialog to allow the user to select the save location\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "default_file_name = file_name_without_extension + \"_risk_concentration_clustering_report\"\n",
    "file_path = filedialog.asksaveasfilename(defaultextension='.xlsx', initialfile=default_file_name)\n",
    "\n",
    "# Write the cluster information to a new sheet in the Excel file\n",
    "with pd.ExcelWriter(file_path) as writer:\n",
    "    clustered_properties.to_excel(writer, sheet_name='Cluster Information', index=False)\n",
    "\n",
    "    # Get cluster counts\n",
    "    cluster_counts = high_risk.groupby('Cluster')['ObjectID'].count().reset_index()\n",
    "    cluster_counts.columns = ['Cluster', 'Count']\n",
    "\n",
    "    # Write cluster counts to new sheet\n",
    "    cluster_counts.to_excel(writer, sheet_name='Cluster Counts', index=False)\n",
    "\n",
    "print(\"Excel write task completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
