{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce524a9b-f4c8-484d-b77e-a7dfa1f88af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Analysis_file loaded in...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read the Excel in\n",
    "analysis_file_df = pd.read_excel(\"filtered_client_file_amfam.xls.xlsx\", engine=\"openpyxl\")\n",
    "print(\"Processing...\")\n",
    "print(\"Analysis_file loaded in...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0845c53-d13d-4012-ad67-575335f3b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations complete...\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the original dataframe\n",
    "original_df = analysis_file_df.copy()\n",
    "\n",
    "# Filter out rows with blank scores\n",
    "analysis_file_df = analysis_file_df.dropna(subset=[\"level_1\", \"level_2\"])\n",
    "\n",
    "# Function to create score distributions\n",
    "def create_score_distributions(df, level_1, level_2, groupby_columns):\n",
    "    # Group by the specified columns and extract the counts for the specified level_1 and level_2 columns\n",
    "    count_stats = df.groupby(groupby_columns)[[level_1, level_2]].count()\n",
    "\n",
    "    # Calculate the percentage distribution and convert it to a decimal\n",
    "    count_stats[\"% distribution\"] = count_stats.groupby(level=groupby_columns[0])[level_1].apply(lambda x: x / x.sum())\n",
    "\n",
    "    # Rename the count column to include the level name\n",
    "    count_stats = count_stats.rename(columns={level_1: f\"{level_1} - count\", level_2: f\"{level_2} - count\"})\n",
    "    return count_stats[[\"% distribution\"]]\n",
    "\n",
    "def create_score_distributions_l1_l2_intersection(df, level_1_col, level_2_col, groupby_columns, return_percentages=True):\n",
    "    grouped_df = df.groupby(groupby_columns).size().reset_index(name='count')\n",
    "    pivot_table = grouped_df.pivot_table(values='count', index=[groupby_columns[0], level_1_col], columns=level_2_col, fill_value=0).reset_index()\n",
    "\n",
    "    if return_percentages:\n",
    "        # Calculate the percentage distribution\n",
    "        score_columns = pivot_table.columns[2:]\n",
    "        for score_year in pivot_table[groupby_columns[0]].unique():\n",
    "            total_count = pivot_table[pivot_table[groupby_columns[0]] == score_year][score_columns].sum().sum()\n",
    "            pivot_table.loc[pivot_table[groupby_columns[0]] == score_year, score_columns] = pivot_table.loc[pivot_table[groupby_columns[0]] == score_year, score_columns].apply(lambda x: x / total_count)\n",
    "\n",
    "    return pivot_table\n",
    "\n",
    "# Function to calculate pilot stats\n",
    "def calculate_pilot_stats(df, original_df):\n",
    "    total_records = len(original_df)\n",
    "    l1_provided = len(df.dropna(subset=[\"level_1\"])) / total_records\n",
    "    l2_provided = len(df.dropna(subset=[\"level_2\"])) / total_records\n",
    "\n",
    "    level_1_describe = df[\"level_1\"].describe()\n",
    "    level_2_describe = df[\"level_2\"].describe()\n",
    "\n",
    "    state_counts = df[\"state\"].value_counts(normalize=True)\n",
    "    \n",
    "    pilot_stats = pd.concat([\n",
    "        pd.Series({\"Total Records\": total_records,\n",
    "                   \"% L1 Provided\": l1_provided,\n",
    "                   \"% L2 Provided\": l2_provided}),\n",
    "        level_1_describe.rename(lambda x: f\"L1 {x.capitalize()}\"),\n",
    "        level_2_describe.rename(lambda x: f\"L2 {x.capitalize()}\"),\n",
    "        state_counts.rename(lambda x: f\"% {x}\")\n",
    "    ])\n",
    "\n",
    "    return pilot_stats.to_frame().T\n",
    "\n",
    "# Calculate pilot stats for the entire dataset\n",
    "pilot_stats = calculate_pilot_stats(analysis_file_df, original_df)\n",
    "\n",
    "# Distributions for the entire dataset\n",
    "entire_dataset_l1 = create_score_distributions(analysis_file_df, \"level_1\", \"l1_risk_level\", [\"level_1\", \"l1_risk_level\"])\n",
    "entire_dataset_l2 = create_score_distributions(analysis_file_df, \"level_2\", \"l2_risk_level\", [\"level_2\", \"l2_risk_level\"])\n",
    "\n",
    "# Distributions for the entire dataset less CA\n",
    "no_ca_df = analysis_file_df[analysis_file_df[\"state\"] != \"CA\"]\n",
    "entire_dataset_no_ca_l1 = create_score_distributions(no_ca_df, \"level_1\", \"l1_risk_level\", [\"score_year\", \"level_1\", \"l1_risk_level\"])\n",
    "entire_dataset_no_ca_l2 = create_score_distributions(no_ca_df, \"level_2\", \"l2_risk_level\", [\"score_year\", \"level_2\", \"l2_risk_level\"])\n",
    "\n",
    "# Distributions for each score_year\n",
    "score_year_l1 = create_score_distributions(analysis_file_df, \"level_1\", \"l1_risk_level\", [\"score_year\", \"level_1\", \"l1_risk_level\"])\n",
    "score_year_l2 = create_score_distributions(analysis_file_df, \"level_2\", \"l2_risk_level\", [\"score_year\", \"level_2\", \"l2_risk_level\"])\n",
    "\n",
    "# For each state\n",
    "for state in analysis_file_df[\"state\"].unique():\n",
    "    state_df = analysis_file_df[analysis_file_df[\"state\"] == state]\n",
    "    state_score_year_l1_l2 = create_score_distributions_l1_l2_intersection(state_df, \"level_1\", \"level_2\", [\"score_year\", \"level_1\", \"level_2\"])\n",
    "\n",
    "# For the \"Score Year L1\" and \"Score Year L2\" tabs\n",
    "score_year_l1_l2 = create_score_distributions_l1_l2_intersection(analysis_file_df, \"level_1\", \"level_2\", [\"score_year\", \"level_1\", \"level_2\"])\n",
    "\n",
    "print(\"Calculations complete...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43dc4c9e-e05e-4730-bc0f-480c5f589693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File shell created...\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(\"score_distributions.xlsx\") as writer:\n",
    "    # Write score year distributions to the workbook\n",
    "    score_year_l1.to_excel(writer, sheet_name=\"Score Year L1\")\n",
    "    score_year_l2.to_excel(writer, sheet_name=\"Score Year L2\")\n",
    "\n",
    "    # Create matrixed distributions by count and percentage\n",
    "    score_year_l1_l2_count = create_score_distributions_l1_l2_intersection(analysis_file_df, \"level_1\", \"level_2\", [\"score_year\", \"level_1\", \"level_2\"], return_percentages=False)\n",
    "    score_year_l1_l2_percentage = create_score_distributions_l1_l2_intersection(analysis_file_df, \"level_1\", \"level_2\", [\"score_year\", \"level_1\", \"level_2\"], return_percentages=True)\n",
    "\n",
    "    # Write matrixed distribution by count for the Score Year L1 and L2 tabs\n",
    "    score_year_l1_l2_count.to_excel(writer, sheet_name=\"Score Year L2\", startrow=score_year_l2.shape[0] + 3, index=False)\n",
    "    score_year_l1_l2_count.to_excel(writer, sheet_name=\"Score Year L1\", startrow=score_year_l1.shape[0] + 3, index=False)\n",
    "\n",
    "    # Write matrixed distribution by percentage for the Score Year L1 and L2 tabs\n",
    "    score_year_l1_l2_percentage.to_excel(writer, sheet_name=\"Score Year L2\", startrow=score_year_l2.shape[0] + 2 + score_year_l1_l2_count.shape[0] + 4, index=False)\n",
    "    score_year_l1_l2_percentage.to_excel(writer, sheet_name=\"Score Year L1\", startrow=score_year_l1.shape[0] + 2 + score_year_l1_l2_count.shape[0] + 4, index=False)\n",
    "\n",
    "    # Write X-CA L1 and X-CA L2 sheets to the workbook\n",
    "    entire_dataset_no_ca_l1.to_excel(writer, sheet_name=\"X-CA L1\", index_label=\"Score Distributions\")\n",
    "    entire_dataset_no_ca_l2.to_excel(writer, sheet_name=\"X-CA L2\", index_label=\"Score Distributions\")\n",
    "\n",
    "    # Distributions for each state\n",
    "    for state in analysis_file_df[\"state\"].unique():\n",
    "        state_df = analysis_file_df[analysis_file_df[\"state\"] == state]\n",
    "\n",
    "        # Calculate distributions for the state\n",
    "        state_l1 = create_score_distributions(state_df, \"level_1\", \"l1_risk_level\", [\"level_1\", \"l1_risk_level\"])\n",
    "        state_l2 = create_score_distributions(state_df, \"level_2\", \"l2_risk_level\", [\"level_2\", \"l2_risk_level\"])\n",
    "\n",
    "        # Calculate score year distributions for the state\n",
    "        state_score_year_l1 = create_score_distributions(state_df, \"level_1\", \"l1_risk_level\", [\"score_year\", \"level_1\", \"l1_risk_level\"])\n",
    "        state_score_year_l2 = create_score_distributions(state_df, \"level_2\", \"l2_risk_level\", [\"score_year\", \"level_2\", \"l2_risk_level\"])\n",
    "\n",
    "        # Save score year distributions for each state\n",
    "        state_score_year_l1.to_excel(writer, sheet_name=f\"State {state} L1\", index_label=\"Score Year Distributions\")\n",
    "        state_score_year_l2.to_excel(writer, sheet_name=f\"State {state} L2\", index_label=\"Score Year Distributions\")\n",
    "\n",
    "        # Calculate and save matrixed distribution for each state\n",
    "        state_score_year_l1_l2 = create_score_distributions_l1_l2_intersection(state_df, \"level_1\", \"level_2\", [\"score_year\", \"level_1\", \"level_2\"], return_percentages=False)\n",
    "        state_score_year_l1_l2.to_excel(writer, sheet_name=f\"State {state} L1\", startrow=state_score_year_l1.shape[0] + 3, index=False)\n",
    "        state_score_year_l1_l2.to_excel(writer, sheet_name=f\"State {state} L2\", startrow=state_score_year_l2.shape[0] + 3, index=False)\n",
    "\n",
    "        # Save percentage distribution matrix for each state\n",
    "        state_score_year_l1_l2_percentage = create_score_distributions_l1_l2_intersection(state_df, \"level_1\", \"level_2\", [\"score_year\", \"level_1\", \"level_2\"], return_percentages=True)\n",
    "        state_score_year_l1_l2_percentage.to_excel(writer, sheet_name=f\"State {state} L1\", startrow=state_score_year_l1.shape[0] + state_score_year_l1_l2.shape[0] + 6, index=False)\n",
    "        state_score_year_l1_l2_percentage.to_excel(writer, sheet_name=f\"State {state} L2\", startrow=state_score_year_l2.shape[0] + state_score_year_l1_l2.shape[0] + 6, index=False)\n",
    "\n",
    "\n",
    "    # Save Pilot Stats to a sheet in the workbook\n",
    "    pilot_stats.to_excel(writer, sheet_name=\"Pilot Stats\", index=False)\n",
    "    \n",
    "print(\"File shell created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe849f0c-7604-4b52-a5b9-77ceda013d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data appended to shell file successfully...\n",
      "the file is in the directory and is called score_distributions...\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# Read the sheets of interest\n",
    "res_l1_state_baselines = pd.read_excel(\"State Preprocessing Distributions.xlsx\", sheet_name=\"Res. L1 State Baselines\", engine=\"openpyxl\")\n",
    "res_l2_state_baselines = pd.read_excel(\"State Preprocessing Distributions.xlsx\", sheet_name=\"Res. L2 State Baselines\", engine=\"openpyxl\")\n",
    "\n",
    "# Function to check if a sheet exists in an Excel file\n",
    "def sheet_exists(file_path, sheet_name):\n",
    "    workbook = openpyxl.load_workbook(file_path, read_only=True)\n",
    "    return sheet_name in workbook.sheetnames\n",
    "\n",
    "# Load the Excel workbook\n",
    "book = openpyxl.load_workbook(\"score_distributions.xlsx\")\n",
    "\n",
    "for state in analysis_file_df[\"state\"].unique():\n",
    "    state_l1_sheet = f\"State {state} L1\"\n",
    "    state_l2_sheet = f\"State {state} L2\"\n",
    "    \n",
    "    if sheet_exists(\"score_distributions.xlsx\", state_l1_sheet) and sheet_exists(\"score_distributions.xlsx\", state_l2_sheet):\n",
    "        # Read the state's L1 and L2 sheets\n",
    "        state_l1_data = pd.read_excel(\"score_distributions.xlsx\", sheet_name=state_l1_sheet, engine=\"openpyxl\")\n",
    "        state_l2_data = pd.read_excel(\"score_distributions.xlsx\", sheet_name=state_l2_sheet, engine=\"openpyxl\")\n",
    "        \n",
    "        # Get the state's L1 and L2 baselines\n",
    "        state_l1_baselines = res_l1_state_baselines[res_l1_state_baselines[\"State\"] == state][\"L1 Distribution\"].reset_index(drop=True)\n",
    "        state_l2_baselines = res_l2_state_baselines[res_l2_state_baselines[\"State\"] == state][\"L2 Distribution\"].reset_index(drop=True)\n",
    "\n",
    "        # Get the existing sheets\n",
    "        ws_l1 = book[state_l1_sheet]\n",
    "        ws_l2 = book[state_l2_sheet]\n",
    "\n",
    "        # Add the \"Industry Baseline\" heading\n",
    "        ws_l1.cell(row=1, column=5, value=\"Industry Baseline\")\n",
    "        ws_l2.cell(row=1, column=5, value=\"Industry Baseline\")\n",
    "\n",
    "        # Clear the old data\n",
    "        for row in ws_l1.iter_rows(min_row=2, min_col=6, max_row=11, max_col=15):\n",
    "            for cell in row:\n",
    "                cell.value = None\n",
    "        for row in ws_l2.iter_rows(min_row=2, min_col=6, max_row=11, max_col=15):\n",
    "            for cell in row:\n",
    "                cell.value = None\n",
    "\n",
    "        # Append new data to the sheets\n",
    "        for index, value in enumerate(state_l1_baselines):\n",
    "            ws_l1.cell(row=index+2, column=5, value=value)\n",
    "        for index, value in enumerate(state_l2_baselines):\n",
    "            ws_l2.cell(row=index+2, column=5, value=value)\n",
    "    else:\n",
    "        print(f\"Worksheets for state '{state}' not found in score_distributions.xlsx\")\n",
    "\n",
    "# Save the updated workbook\n",
    "book.save(\"score_distributions.xlsx\")\n",
    "book.close()\n",
    "print(\"All data appended to shell file successfully...\")\n",
    "print(\"the file is in the directory and is called score_distributions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf54c3-1508-4189-ba11-2f3a2df96856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
