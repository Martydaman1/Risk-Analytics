{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2c706017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and leverage the imported file for analysis\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "Tk().withdraw()\n",
    "file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eff71cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base name of the file\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Remove the extension from the file name\n",
    "file_name_without_extension = os.path.splitext(file_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e003ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hartford pilot data] Zesty 100K Sample - External 01122023.xlsx\n",
      "Index(['Ref', 'Effective Date', 'Street', 'City', 'State', 'Zip', 'Lat',\n",
      "       'Long'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(file_name)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3661b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the address columns\n",
    "address_columns = {\n",
    "    'street_and_house_number': ['Addr1','Risk Address','Street'],\n",
    "    'city': ['City','Risk City','city'],\n",
    "    'state_abbreviation': ['State','StateProvCd','Risk State'],\n",
    "    'postal_code': ['Risk Zip Code','PostalCd','Zip','Zip Code'],\n",
    "    'latitude': ['Lat', 'Risk Lat', 'lat'],\n",
    "    'longitude': ['Long','Risk Long','long']\n",
    "    }\n",
    "    \n",
    "# Check if any of the address column names are in the DataFrame\n",
    "address_column_mask = df.columns.isin(\n",
    "    address_columns['street_and_house_number'] +\n",
    "    address_columns['city'] +\n",
    "    address_columns['state_abbreviation'] +\n",
    "    address_columns['postal_code']\n",
    ")\n",
    "\n",
    "# Get the name of the column to use for each component\n",
    "street_and_house_number_col = list(set(df.columns) & set(address_columns['street_and_house_number']))[0]\n",
    "city_col = list(set(df.columns) & set(address_columns['city']))[0]\n",
    "state_abbreviation_col = list(set(df.columns) & set(address_columns['state_abbreviation']))[0]\n",
    "postal_code_col = list(set(df.columns) & set(address_columns['postal_code']))[0]\n",
    "\n",
    "# Select the first column that exists in the DataFrame\n",
    "for column, column_names in address_columns.items():\n",
    "    match = df.columns[df.columns.isin(column_names)].tolist()\n",
    "    if match:\n",
    "        address_columns[column] = match[0]\n",
    "\n",
    "if not any(address_column_mask):\n",
    "    raise ValueError('None of the specified address columns were found in the DataFrame')\n",
    "\n",
    "# Concatenate the address components into a single address string\n",
    "df['address'] = (\n",
    "    df[address_columns['street_and_house_number']].astype(str) + ', ' +\n",
    "    df[address_columns['city']].astype(str) + ', ' +\n",
    "    df[address_columns['state_abbreviation']].astype(str) + ' ' +\n",
    "    df[address_columns['postal_code']].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0082819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag duplicates in the address column\n",
    "df['address_duplicate'] = df['address'].duplicated()\n",
    "    \n",
    "# Count the number of duplicates\n",
    "num_address_duplicates = df['address_duplicate'].sum()\n",
    "\n",
    "# Calculate the percentage of duplicates\n",
    "percent_address_duplicates = num_address_duplicates / df.shape[0] * 100\n",
    "    \n",
    "# Repeat the same steps for the latitude and longitude columns\n",
    "df['lat_long'] = df[address_columns['latitude']].astype(str) + ', ' + df[address_columns['longitude']].astype(str)\n",
    "df['lat_long_duplicate'] = df['lat_long'].duplicated()\n",
    "num_lat_long_duplicates = df['lat_long_duplicate'].sum()\n",
    "percent_lat_long_duplicates = num_lat_long_duplicates / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "252bdc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate addresses: 115\n",
      "Percentage of duplicate addresses: 0.11499999999999999\n",
      "Number of duplicate lat/long pairs: 1221\n",
      "Percentage of duplicate lat/long pairs: 1.221\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print('Number of duplicate addresses:', num_address_duplicates)\n",
    "print('Percentage of duplicate addresses:', percent_address_duplicates)\n",
    "print('Number of duplicate lat/long pairs:', num_lat_long_duplicates)\n",
    "print('Percentage of duplicate lat/long pairs:', percent_lat_long_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e2bf1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible names of the effective date columns\n",
    "effective_date_columns = ['Effective Date', 'EffDate', 'eff_date']\n",
    "\n",
    "# Check if any of the effective date column names are in the DataFrame\n",
    "effective_date_column_mask = df.columns.isin(effective_date_columns)\n",
    "\n",
    "# Get the name of the column to use for the effective date\n",
    "effective_date_col = list(set(df.columns) & set(effective_date_columns))[0]\n",
    "\n",
    "# Select the first column that exists in the DataFrame\n",
    "for column, column_names in {'effective_date': effective_date_columns}.items():\n",
    "    match = df.columns[df.columns.isin(column_names)].tolist()\n",
    "    if match:\n",
    "        effective_date_col = match[0]\n",
    "\n",
    "if not any(effective_date_column_mask):\n",
    "    raise ValueError('None of the specified effective date columns were found in the DataFrame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a617f5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of records with effective date prior to 2020: 0.83756\n",
      "Count of records with effective date prior to 2020: 83756\n"
     ]
    }
   ],
   "source": [
    "# Convert the effective date column to datetime format\n",
    "df[effective_date_col] = pd.to_datetime(df[effective_date_col], errors='coerce')\n",
    "\n",
    "# Find the index of the effective date column\n",
    "col_index = df.columns.get_loc(effective_date_col)\n",
    "\n",
    "# Create a new output flag column with values True if the effective date is prior to 2020, False otherwise\n",
    "df.insert(loc=col_index + 1, column='effective_date_prior_to_2020', value=df[effective_date_col] < '2020-01-01')\n",
    "\n",
    "# Calculate the percentage of records with the output flag set to True\n",
    "percent_records = df['effective_date_prior_to_2020'].mean() * 1\n",
    "\n",
    "print(f\"Percentage of records with effective date prior to 2020: {percent_records}\")\n",
    "\n",
    "# Count the number of records with effective date prior to 2020\n",
    "count_records = df[df['effective_date_prior_to_2020'] == True].shape[0]\n",
    "\n",
    "print(f\"Count of records with effective date prior to 2020: {count_records}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "da83accf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel write task completed.\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with the results\n",
    "duplicate_results = {'Duplicate Addresses': [num_address_duplicates],\n",
    "                     'Percentage of Duplicate Addresses': percent_address_duplicates / 100,\n",
    "                     'Duplicate Lat/Long Pairs': [num_lat_long_duplicates],\n",
    "                     'Percentage of Duplicate Lat/Long Pairs': percent_lat_long_duplicates / 100,\n",
    "                     'Percentage Before 2020': percent_records,\n",
    "                     'Count Before 2020': count_records}\n",
    "\n",
    "duplicate_results_df = pd.DataFrame(duplicate_results)\n",
    "\n",
    "# Create a file dialog to allow the user to select the save location\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "default_file_name = file_name_without_extension + \"_duplicate_QA_Check.xlsx\"\n",
    "file_path = filedialog.asksaveasfilename(defaultextension='.xlsx', initialfile=default_file_name)\n",
    "\n",
    "\n",
    "# Write the original data to a new Excel file\n",
    "df.to_excel(file_path, engine='openpyxl', index=False)\n",
    "\n",
    "# Append the results to the same Excel file\n",
    "book = openpyxl.load_workbook(file_path)\n",
    "writer = pd.ExcelWriter(file_path, engine='openpyxl')\n",
    "writer.book = book\n",
    "duplicate_results_df.to_excel(writer, sheet_name='Duplicate Results Report', index=False)\n",
    "writer.save()\n",
    "writer.close()\n",
    "print(\"Excel write task completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f4987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
